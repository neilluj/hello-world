import os, zipfile, re, gc
import numpy as np
import pandas as pd
import fiona
from shapely.geometry import shape
from shapely.validation import make_valid
from pyproj import CRS, Transformer
from sklearn.neighbors import BallTree

def _ensure_str_5(x):
    if pd.isna(x): return np.nan
    s = str(x).strip()
    s = re.sub(r"[^\d]", "", s)
    if len(s) >= 5:
        s = s[:5]
    return s.zfill(5)

def _build_from_parts(df, ent_col, mun_col):
    ce = df[ent_col].astype(str).str.replace(r"[^\d]", "", regex=True).str.zfill(2)
    cm = df[mun_col].astype(str).str.replace(r"[^\d]", "", regex=True).str.zfill(3)
    return (ce + cm).str[:5]

def _open_vector(path):
    if path.lower().endswith(".zip"):
        extract_dir = os.path.splitext(path)[0] + "_extracted"
        os.makedirs(extract_dir, exist_ok=True)
        with zipfile.ZipFile(path, "r") as z:
            z.extractall(extract_dir)
        shp = [os.path.join(extract_dir, f) for f in os.listdir(extract_dir) if f.lower().endswith(".shp")]
        if not shp: raise FileNotFoundError("El ZIP no contiene .shp")
        return shp[0]
    if not path.lower().endswith(".shp"):
        raise ValueError("Proporciona .shp o .zip con el .shp.")
    return path

def _detect_key_cols(fields, sample_props):
    for c in fields:
        if c.upper()=="CVEGEO": return ("single", c)
    ent, mun = None, None
    for c in fields:
        u = c.upper()
        if u in ("CVE_ENT","CVEENT","ENTIDAD","CVE_ENTIDAD","CVE_ENTI","CVEGEO_ENT"): ent = ent or c
        if u in ("CVE_MUN","CVEMUN","MUN","MUNICIPIO","CVE_MUNICIP"): mun = mun or c
    if ent and mun: return ("concat", (ent, mun))
    for c in fields:
        vals = [str(r.get(c,"")).strip() for r in sample_props]
        ratio = sum(1 for v in vals if re.fullmatch(r"\d{5}", re.sub(r"[^\d]","",v))) / max(1,len(vals))
        if ratio > 0.6: return ("single", c)
    raise ValueError("No pude detectar columna de clave municipal.")

def _centroids_from_shp(shp_path):
    rows = []
    with fiona.open(shp_path,"r") as src:
        crs = CRS.from_wkt(src.crs_wkt) if src.crs_wkt else (CRS.from_user_input(src.crs) if src.crs else None)
        fields = list(src.schema["properties"].keys())
        sample = []
        for i, feat in enumerate(src):
            sample.append(feat["properties"])
            if i>=199: break
    with fiona.open(shp_path,"r") as src:
        mode, keyinfo = _detect_key_cols(fields, sample)
        to_wgs84 = None
        if crs and not crs.equals(CRS.from_epsg(4326)):
            to_wgs84 = Transformer.from_crs(crs, CRS.from_epsg(4326), always_xy=True)
        for feat in src:
            props = feat["properties"]
            geom = feat["geometry"]
            if geom is None: continue
            g = make_valid(shape(geom))
            c = g.centroid
            cx, cy = c.x, c.y
            if to_wgs84 is not None:
                cx, cy = to_wgs84.transform(cx, cy)
            if mode=="single":
                cve = _ensure_str_5(props[keyinfo])
            else:
                ce, cm = keyinfo
                cve = _ensure_str_5(str(props[ce]) + str(props[cm]))
            rows.append({"cve_mun": cve, "lat": cy, "lon": cx})
    df = pd.DataFrame(rows).drop_duplicates("cve_mun").reset_index(drop=True)
    return df

def distancia_al_tratado_mas_cercano_con_centroides(
    df_munis: pd.DataFrame,
    geofile_path: str,
    *,
    ent_col=None, mun_col=None,
    on_missing="error",      # "error" | "warn_fill_na"
    chunk_size=200_000       # procesa consultas en lotes para reducir RAM
) -> pd.DataFrame:
    """
    Devuelve df con columnas lat, lon y dist_km_nearest_treated.
    Optimizado para bajo uso de memoria: float32 + consultas por lotes.
    """
    if "flg_tratado" not in df_munis.columns:
        raise ValueError("Falta 'flg_tratado' en df_munis.")
    df = df_munis.copy()

    # Construcción/normalización de cve_mun
    if "cve_mun" in df.columns:
        df["cve_mun"] = df["cve_mun"].apply(_ensure_str_5)
    elif ent_col and mun_col and ent_col in df.columns and mun_col in df.columns:
        df["cve_mun"] = _build_from_parts(df, ent_col, mun_col).apply(_ensure_str_5)
    else:
        raise ValueError("Proporciona 'cve_mun' o (ent_col, mun_col).")

    df["flg_tratado"] = (df["flg_tratado"].astype(float) > 0).astype(np.uint8)

    # Centroides
    shp_path = _open_vector(geofile_path)
    cent = _centroids_from_shp(shp_path)

    merged = df.merge(cent, on="cve_mun", how="left", validate="m:1")

    # Diagnóstico de faltantes
    miss = merged["lat"].isna()
    if miss.any():
        falt = merged.loc[miss, "cve_mun"].dropna().unique().tolist()
        print(f"[Diagnóstico] {len(falt)} claves sin centroide. Ejemplos:", falt[:30])
        if on_missing == "error":
            raise ValueError("Hay claves municipales sin centroide. Usa on_missing='warn_fill_na' para continuar.")
        # si warn_fill_na, seguimos y esas filas quedarán con NaN en distancia

    # Si no hay tratados, no hay distancia que calcular
    if merged["flg_tratado"].sum() == 0:
        merged["dist_km_nearest_treated"] = np.nan
        return merged

    # Mantén solo filas con lat/lon válidos para el cálculo
    ok = merged.dropna(subset=["lat","lon"]).copy()

    # === Minimiza RAM: usa float32 y evita copias ===
    lat = np.deg2rad(ok["lat"].to_numpy(dtype=np.float32, copy=False))
    lon = np.deg2rad(ok["lon"].to_numpy(dtype=np.float32, copy=False))
    treated = ok["flg_tratado"].to_numpy(dtype=bool, copy=False)

    # Conjunto tratado (para el árbol)
    Xt = np.column_stack((lat[treated], lon[treated])).astype(np.float32, copy=False)
    tree = BallTree(Xt, metric="haversine")

    # Consulta por lotes para no reventar RAM
    R_km = np.float32(6371.0088)
    dist_out = np.empty(ok.shape[0], dtype=np.float32)

    n = ok.shape[0]
    start = 0
    while start < n:
        end = min(start + chunk_size, n)
        Xq = np.column_stack((lat[start:end], lon[start:end])).astype(np.float32, copy=False)
        dist_rad, _ = tree.query(Xq, k=1)
        dist_km = (dist_rad.reshape(-1).astype(np.float32, copy=False) * R_km)
        # Si el propio municipio está tratado => 0
        dist_km = np.where(treated[start:end], np.float32(0.0), dist_km)
        dist_out[start:end] = dist_km
        # libera referencias intermedias
        del Xq, dist_rad, dist_km
        gc.collect()
        start = end

    ok["dist_km_nearest_treated"] = dist_out

    # Re-une con el original (las filas sin lat/lon se quedarán NaN)
    merged = merged.drop(columns=["dist_km_nearest_treated"], errors="ignore").merge(
        ok[["cve_mun","dist_km_nearest_treated"]], on="cve_mun", how="left"
    )
    return merged